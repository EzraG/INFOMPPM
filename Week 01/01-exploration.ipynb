{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”¬ Data exploration and preparation\n",
    "In this notebook, we'll examine the dataset and create a subset of it for further analysis. The dataset was relatively clean when downloaded, though we addressed some problematic delimiter issues for you. If you're interested in tackling these issues firsthand, the original dataset is available at the [Book-Crossing Dataset](http://www2.informatik.uni-freiburg.de/~cziegler/BX/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading the data\n",
    "Load the three datasets and explore the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_ratings = pd.read_csv('data/BX-Book-Ratings.csv', sep=';', encoding='latin-1')\n",
    "df_books = pd.read_csv('data/BX-Books.csv', low_memory=False, sep=';', encoding='latin-1')\n",
    "df_users = pd.read_csv('data/BX-Users.csv', low_memory=False, sep=';', encoding='latin-1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cleaning the data\n",
    "Ensure that all reviews are linked to a book. Investigate whether there are any reviews that lack a corresponding book or user. Verify the accuracy of author names and identify any anomalies, such as users who have submitted an unusually high number of reviews. Describe the process you followed to clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1149779 different ratings in the database, while there are 1031175 reviews of existing books.\n",
      "There are 1149779 different ratings in the database, while there are 1149779 reviews of existing users.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "User-ID          0\n",
       "Location         0\n",
       "Age         110762\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ensure that all reviews are linked to an existing book\n",
    "df_merged_book = pd.merge(df_ratings, df_books, on='ISBN', how='inner')\n",
    "print('There are', len(df_ratings), 'different ratings in the database, while there are', len(df_merged_book), 'reviews of existing books.')\n",
    "#So some books are not existing\n",
    "\n",
    "#Ensure that all reviews are linked to an existing user\n",
    "df_merged_user = pd.merge(df_ratings, df_users, on='User-ID', how='inner')\n",
    "print('There are', len(df_ratings), 'different ratings in the database, while there are', len(df_merged_user), 'reviews of existing users.')\n",
    "#So all users exists\n",
    "\n",
    "#Find missing values\n",
    "df_ratings.isna().sum() #No missing values\n",
    "df_books.isna().sum()   #In total 6 missing values for the Author, Publisher and Large Image URL\n",
    "df_users.isna().sum()   #In total 110762 missing values for the variable Age\n",
    "\n",
    "#Frequency\n",
    "df_ratings['User-ID'].value_counts()    #There is one user who gave over thousand ratings, namely User-ID = 11676"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Subsetting the data\n",
    "The publication accompanied with this dataset [Improving Recommendation Lists Through Topic Diversification](http://www2.informatik.uni-freiburg.de/~cziegler/BX/WWW-2005-Preprint.pdf) by Cai-Nicolas Ziegler, Sean M. McNee, Joseph A. Konstan, Georg Lausen; describes the process of subsetting (condensation steps) the dataset as follows (p5): \n",
    "\n",
    "> Hence, we discarded all books missing taxonomic descriptions, along with all ratings referring to them. Next, we also removed book titles with fewer than 20 overall mentions. Only community members with at least five ratings each were kept. \n",
    "\n",
    "Investigate the significance of these parameters for the dataset as a whole. Additionally, decide whether to include implicit ratings (where Book-Rating equals 0) in your final dataset. Consider the potential consequences of this choice. Would you opt to exclude them prior to assessing other parameters, or would it be more appropriate to exclude them later?\n",
    "\n",
    "Although the publication outlines the expected dimensions of the resulting dataset, it's acceptable if your findings vary at this stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11676     1029\n",
       "16795      234\n",
       "95359      201\n",
       "104636     163\n",
       "153662     139\n",
       "          ... \n",
       "117963       5\n",
       "117553       5\n",
       "228154       5\n",
       "116599       5\n",
       "276681       5\n",
       "Name: User-ID, Length: 4238, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop review if rating is zero\n",
    "df_ratings = df_ratings[df_ratings['Book-Rating'] != 0]\n",
    "\n",
    "#Remove titles with less than 20 mentions\n",
    "ISBN_freq = df_ratings['ISBN'].value_counts() >= 20\n",
    "df_ratings = df_ratings[df_ratings['ISBN']. isin(ISBN_freq[ISBN_freq].index)]\n",
    "df_ratings['ISBN'].value_counts()   #to check\n",
    "\n",
    "#Only keep members with at least five ratings\n",
    "user_freq = df_ratings['User-ID'].value_counts() >= 5\n",
    "df_ratings = df_ratings[df_ratings['User-ID']. isin(user_freq[user_freq].index)]\n",
    "df_ratings['User-ID'].value_counts()   #to check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Extra step\n",
    "Examine the `BX-Books.csv` file specifically for the book Robots and _Empire by Isaac Asimov_. Identify any issues you come across. Would you address these issues?\n",
    "\n",
    "Given that this could pose a problem for our dataset, consider how you would resolve it. You may need to revisit step 2 if you decide to undertake this additional step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19463</th>\n",
       "      <td>0586062009</td>\n",
       "      <td>Robots and Empire</td>\n",
       "      <td>Isaac Asimov</td>\n",
       "      <td>1986</td>\n",
       "      <td>HarperCollins</td>\n",
       "      <td>http://images.amazon.com/images/P/0586062009.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0586062009.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0586062009.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83090</th>\n",
       "      <td>0345328949</td>\n",
       "      <td>Robots and Empire</td>\n",
       "      <td>Isaac Asimov</td>\n",
       "      <td>1991</td>\n",
       "      <td>Del Rey Books</td>\n",
       "      <td>http://images.amazon.com/images/P/0345328949.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0345328949.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0345328949.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136152</th>\n",
       "      <td>0385190921</td>\n",
       "      <td>Robots and Empire</td>\n",
       "      <td>Isaac Asimov</td>\n",
       "      <td>1985</td>\n",
       "      <td>Smithmark Pub</td>\n",
       "      <td>http://images.amazon.com/images/P/0385190921.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0385190921.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0385190921.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ISBN         Book-Title   Book-Author Year-Of-Publication  \\\n",
       "19463   0586062009  Robots and Empire  Isaac Asimov                1986   \n",
       "83090   0345328949  Robots and Empire  Isaac Asimov                1991   \n",
       "136152  0385190921  Robots and Empire  Isaac Asimov                1985   \n",
       "\n",
       "            Publisher                                        Image-URL-S  \\\n",
       "19463   HarperCollins  http://images.amazon.com/images/P/0586062009.0...   \n",
       "83090   Del Rey Books  http://images.amazon.com/images/P/0345328949.0...   \n",
       "136152  Smithmark Pub  http://images.amazon.com/images/P/0385190921.0...   \n",
       "\n",
       "                                              Image-URL-M  \\\n",
       "19463   http://images.amazon.com/images/P/0586062009.0...   \n",
       "83090   http://images.amazon.com/images/P/0345328949.0...   \n",
       "136152  http://images.amazon.com/images/P/0385190921.0...   \n",
       "\n",
       "                                              Image-URL-L  \n",
       "19463   http://images.amazon.com/images/P/0586062009.0...  \n",
       "83090   http://images.amazon.com/images/P/0345328949.0...  \n",
       "136152  http://images.amazon.com/images/P/0385190921.0...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_books[df_books['Book-Title'] == 'Robots and Empire']\n",
    "#This book has been published by three different companies, in different years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Save the new dataset(s)\n",
    "Save the dataset(s) in distinct named CSV-files for later usage. Move the file(s) to the data directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings.to_csv('data/BX-Book-Ratings-Subset.csv', index=False, sep=';')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37c10f95d263926787ebf1d430d11186fc6b9bac835b8518e0b5006ed24f0c36"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
